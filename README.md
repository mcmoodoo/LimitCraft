> ç´”å¤ªã•ã‚“ã®ã‚ˆã†ãªå„ªç§€ãªã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã¨ãƒãƒ¼ãƒ ã‚’çµ„ã‚ã¦ã€æœ¬å½“ã«æ„Ÿè¬ã—ã¦ã„ã¾ã™ã€‚ã“ã‚Œã‹ã‚‰ä¸€ç·’ã«ç´ æ™´ã‚‰ã—ã„ã‚‚ã®ã‚’ä½œã£ã¦ã„ã‘ã‚‹ã®ãŒæ¥½ã—ã¿ã§ã™ã€‚

# ğŸ® 1inch Limit Order - Arbitrum ğŸŒ¸

A complete orderbook application for creating and managing 1inch limit orders on Arbitrum. Features include order creation, automated order filling, and a React frontend with Web3 wallet integration.

## ğŸ¯ Project Structure

â›©ï¸ **`api/`** - Elysia.js backend API for order management
â›©ï¸ **`ui/`** - React frontend with RainbowKit wallet integration
â›©ï¸ **`db/`** - PostgreSQL database layer with Drizzle ORM
â›©ï¸ **`resolver/`** - Automated order resolver and filler
â›©ï¸ **`scripts/`** - Utility scripts
â›©ï¸ **`contracts/`** - Foundry smart contracts with 1inch integration

## ğŸ—ï¸ Smart Contracts Setup

The `contracts/` folder contains Foundry-based smart contracts that integrate with the 1inch Limit Order Protocol.

### ğŸ”§ Prerequisites for Contracts

ğŸ‹ [Foundry](https://book.getfoundry.sh/getting-started/installation) - Ethereum development toolkit
ğŸ‹ Git - For submodule dependencies

### ğŸš€ Contracts Quick Start

```bash
# Install Foundry (if not already installed)
curl -L https://foundry.paradigm.xyz | bash
foundryup

# Initialize git submodules (if not done in main setup)
git submodule update --init --recursive

# Navigate to contracts directory
cd contracts

# Install local dependencies (forge-std, etc.)
forge install

# Build contracts
forge build

# Run tests
forge test

# Run tests with verbose output
forge test -vv
```

### ğŸ“¦ Dependencies

The contracts folder includes these key dependencies:

ğŸŒŸ **1inch Limit Order Protocol** - Core limit order functionality
ğŸŒŸ **OpenZeppelin Contracts** - Standard secure contract implementations  
ğŸŒŸ **1inch Solidity Utils** - Utility libraries for 1inch integration

Dependencies are managed as git submodules in `lib/`:

## ğŸ“‹ Prerequisites

ğŸ‹ Bun runtime
ğŸ‹ Node.js (for package compatibility)
ğŸ‹ Podman or Docker (for PostgreSQL)
ğŸ‹ Just command runner (optional, for database recipes)

## ğŸš€ Quick Start

### 1ï¸âƒ£ Database Setup ğŸ—„ï¸

Create and start a local PostgreSQL container:

```bash
# Using Just recipes (recommended)
just run-postgres-container

# Or manually with Podman
podman run --name our-limit-order-db \
  -e POSTGRES_USER=postgres \
  -e POSTGRES_PASSWORD=postgres \
  -e POSTGRES_DB=our-limit-order-db \
  -p 5432:5432 \
  -d postgres:16
```

Initialize the database:

```bash
cd db
bun run setup
```

### 2ï¸âƒ£ Application Setup âš™ï¸

Initialize git submodules (required for smart contracts):

```bash
# Initialize and update all git submodules
git submodule update --init --recursive
```

Install dependencies:

```bash
bun install
```

Start development servers (API + Frontend):

```bash
bun run dev
```

### 3ï¸âƒ£ Order Resolver (Optional) ğŸ¤–

To enable automated order filling:

```bash
cd resolver
cp .env.example .env
# Edit .env with your private key and 1inch API key
bun install
bun run start
```

## ğŸ“œ Available Scripts

### ğŸ¯ Main Scripts

ğŸŒŸ `bun run dev` - Start both API and frontend concurrently
ğŸŒŸ `bun run dev:api` - Start API server only (watch mode)
ğŸŒŸ `bun run dev:ui` - Start frontend only
ğŸŒŸ `bun run start` - Run production build
ğŸŒŸ `bun test` - Run tests

### ğŸ—ï¸ Build & Production

ğŸ”¨ `bun run build` - Build TypeScript to dist/
ğŸ”¨ `bun run build:prod` - Full production build (install, fix, check, clean, build)
ğŸ”¨ `bun run clean` - Remove dist/ directory
ğŸ”¨ `bun run rebuild` - Clean everything and rebuild from scratch

### âœ¨ Code Quality

ğŸ¨ `bun run typecheck` - TypeScript type checking
ğŸ¨ `bun run lint` - Lint code with Biome
ğŸ¨ `bun run format` - Format code with Biome
ğŸ¨ `bun run lint:fix` - Fix linting issues
ğŸ¨ `bun run check` - Run typecheck + lint
ğŸ¨ `bun run fix` - Run format + lint:fix

### ğŸ­ Infrastructure

ğŸ”§ `bun run redis` - Start Redis container via Podman

## ğŸ—ƒï¸ Database Management

### ğŸ˜ PostgreSQL Container Management

Using Just recipes:

```bash
# Start PostgreSQL container
just run-postgres-container

# Connect to local database
just psql-connect-local

# Connect to remote database (using env vars)
just psql-connect-remote

# Stop and remove container
just rm-postgres-container
```

### âš¡ Database Operations

```bash
cd db

# Initialize database and create tables
bun run setup

# Create database only
bun run init

# Create tables only
bun run create-tables

# Reset database (drop all tables)
bun run reset

# Open Drizzle Studio
bun run studio
```

## ğŸ¤– Order Resolver

The resolver automatically monitors the database for pending orders and fills profitable ones.

### ğŸ› ï¸ Setup

```bash
cd resolver
cp .env.example .env
# Configure your private key and API keys
bun install
```

### ğŸ’« Usage

```bash
# Start resolver
bun run start

# Development mode with auto-reload
bun run dev
```

### âš™ï¸ Configuration

ğŸ”‘ Key environment variables:

ğŸŒ `RESOLVER_PRIVATE_KEY` - Private key for resolver wallet
ğŸŒ `ONE_INCH_API_KEY` - 1inch API key for price data
ğŸŒ `MIN_PROFIT_WEI` - Minimum profit threshold (default: 0.05 ETH)
ğŸŒ `POLL_INTERVAL_MS` - How often to check orders (default: 30s)

## ğŸŒŠ Architecture Flow

1ï¸âƒ£ **Order Creation**: User creates order via frontend â†’ API saves to database
2ï¸âƒ£ **Order Monitoring**: Resolver polls database for pending orders
3ï¸âƒ£ **Profitability Check**: Resolver checks market prices via 1inch API
4ï¸âƒ£ **Order Filling**: Profitable orders are filled via 1inch contract
5ï¸âƒ£ **Status Updates**: Database updated with fill status

## ğŸ’¬ Suggested on discord

You need to make sure you have the proper feeTaker extension when submitting the limit order
cc @Rashid | X:mcmoodoo @abzel23 @hwang Lingo @Darius.TM ğŸ¥· @di é¾™å°å° @sajal

essentially just use the latest verison of the @1inch/fusion-sdk and the createOrder function should handle building the feeTaker extension. This does require an extra API call to get the fee, but you can also cache the request, if the API rejects the order it's likely the whitelist changed or fee tier changed and you'll have to re-fetch the data anyway
